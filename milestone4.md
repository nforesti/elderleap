# Milestone 4

## Actions
1. The first non-trivial action is on the Dashboard page. In this page, the user can interact with categories and subcategories of words through the written word as well as images. By navigating through the categories and clicking on the category, the user will be guded to the images/subcategories that they may be looking for. The user can then click on any image, and the browser will read that out loud. Furthermore, for each category, there are a list of related actions, sentences, or wrods. Hence, the user can click on an image/noun/word and then a related action/verb. Both will be read aloud, and this will help the user communicate as well as possibly learn connections between images, words, and actions.
2. The second non-trivial action is the keyboard page. Here, the user can type in any amount of text. The user can then request the browser to speak the text aloud. The user also has the option to save the text to view it later. All saved text from the past is visible below, and all of them can be clicked on and spoken aloud. They can also be deleted if the user no longer wants the saved messages.

## Screenshots of UI Webpages

### (1) Home Page
For our home page, we simplified the features displayed in the three center boxes. Instead of describing each functionality in detail, 
we identified the key highlights of our app and wrote a one sentence description. We removed the ASL feature since we were not able to get access to the youtube videos and incorporate them into our app. 

![image](https://drive.google.com/uc?export=view&id=1ta8vSm5mGWSRazDNvi9YnjSoM01ymB4p)

### (2) Dashboard - Displays categories
We added a title and description to this page to orient the user to what actions they can do on this page. We also changed the configuration of the yellow boxes to have a consistent height and width so that one category doesn't stand out more than another. The boxes are now in rows and columns instead of a fitting collage.

![image](https://drive.google.com/uc?export=view&id=1AY-2ZZJPjBgglfeBubhSmF1Z0GWu0DUo)

### Display subcategories
The main feature we added to this page is a list of suggested words related to each category displayed at the bottom of the page. This allows for a more informative interaction than simple clicking on images.  The suggested words, when clicked on, will be spoken by the browser. For next week, we hope to create a drag and drop functionality for the user to be able to make sentences, and press "speak" to speak all of it.

![image](https://drive.google.com/uc?export=view&id=1SmIU6iyEOU2XOFmSgejXpcE5wnPTXd6x)

### (3) Keyboard
Before, this page just had functionality where the user could type in and play what was typed in. Now, this page is hooked up to Firebase. A user can save the message, and it will be added to Firebase as well as the queue of messages bellow. All of the messages below can be clicked on (which will make the browser speak the message). All of the below messages can also be deleted (which will delete not only from the queue but also from firebase).

![image](https://drive.google.com/uc?export=view&id=1pUFeU6ZkIkmVpUwHkny_W_gFOE2ki2T_)

### (4) About Page
Finally, we added content to our About Page describing the different features of our app and how we hope to accomodate our intended users.

![image](https://drive.google.com/uc?export=view&id=1LrB58UL2yXbLrYc5BZJ5t41zClEW1zTV)
